{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "real-world-data-representation-with-tensors.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNSjhpZdSeXNncIu7ibT6J7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahiakela/deep-learning-with-pytorch/blob/4-real-world-data-representation-with-tensors/real_world_data_representation_with_tensors.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YprFwmUzY0s_",
        "colab_type": "text"
      },
      "source": [
        "# Real-world data representation with tensors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kFTuRDLTZA0H",
        "colab_type": "text"
      },
      "source": [
        "Tensors are the building blocks for data in PyTorch. Neural networks take tensors in input and produce tensors as outputs. In fact, all operations within a neural network and during optimization are operations between tensors, and all parameters (such as weights and biases) in a neural network are tensors. Having a good sense of how to perform operations on tensors and index them effectively is central to using tools like PyTorch successfully.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JbLJnzouZTWq",
        "colab_type": "text"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vj5XF2J-ZfEW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import csv"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W9twn_K1oNhw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.set_printoptions(edgeitems=2, precision=2)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n-eh5hVNZk8W",
        "colab_type": "text"
      },
      "source": [
        "## Tabular data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Suf97x-IZmWb",
        "colab_type": "text"
      },
      "source": [
        "The simplest form of data you’ll encounter in your machine learning job is sitting in a spreadsheet, in a CSV (comma-separated values) file, or in a database. Whatever the medium, this data is a table containing one row per sample (or record), in which columns contain one piece of information about the sample.\n",
        "\n",
        "Columns may contain numerical values, such as temperatures at specific locations, or labels, such as a string expressing an attribute of the sample (like \"blue\"). **Therefore, tabular data typically isn’t homogeneous; different columns don’t have the same type.** You might have a column showing the weight of apples and another encoding their color in a label.\n",
        "\n",
        "PyTorch tensors, on the other hand, are homogeneous. Other data science packages, such as Pandas, have the concept of the data frame, an object representing a data set with named, heterogenous columns. By contrast, information in PyTorch is encoded as a number, typically floating-point (though integer types are supported as well).\n",
        "\n",
        "Numeric encoding is deliberate, because neural networks are mathematical entities that take real numbers as inputs and produce real numbers as output through successive application of matrix multiplications and nonlinear functions.\n",
        "\n",
        "**Your first job as a deep learning practitioner, therefore, is to encode heterogenous, real-world data in a tensor of floating-point numbers, ready for consumption by a neural network.**\n",
        "\n",
        "We start with something fun: wine. The Wine Quality data set is a freely available table containing chemical characterizations of samples of vinho verde (a wine from northern Portugal) together with a sensory quality score. You can download the data set for white wines at https://archive.ics.uci.edu/ml/machine-learning-databases/winequality/winequality-white.csv.\n",
        "\n",
        "<img src='https://github.com/rahiakela/img-repo/blob/master/deep-learning-with-pytorch/wine-datasets.png?raw=1' width='800'/>\n",
        "\n",
        "You hope to find a relationship between one of the chemical\n",
        "columns in your data and the quality column. Here, you’re expecting to see quality increase as sulfur decreases.\n",
        "\n",
        "Before you can get to that observation, however, you need to be able to examine\n",
        "the data in a more usable way than opening the file in a text editor. We’ll show you how to load the data by using Python and then turn it into a PyTorch tensor."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K06FFj1nqwqm",
        "colab_type": "text"
      },
      "source": [
        "### Loading dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tm8Z1t0QqzPh",
        "colab_type": "text"
      },
      "source": [
        "Python offers several options for loading a CSV file quickly. Three popular options are:\n",
        "\n",
        "* The csv module that ships with Python\n",
        "* NumPy\n",
        "* Pandas\n",
        "\n",
        "The third option is the most time- and memory-efficient, but we’ll avoid introducing an additional library into your learning trajectory merely to load a file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_PFNWCa2rllI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "d8ccf9e8-1ead-4572-dfd7-4fe5d8d92a33"
      },
      "source": [
        "! wget https://raw.githubusercontent.com/deep-learning-with-pytorch/dlwpt-code/master/data/p1ch4/tabular-wine/winequality-white.csv"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-07-06 04:59:02--  https://raw.githubusercontent.com/deep-learning-with-pytorch/dlwpt-code/master/data/p1ch4/tabular-wine/winequality-white.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 264426 (258K) [text/plain]\n",
            "Saving to: ‘winequality-white.csv’\n",
            "\n",
            "\rwinequality-white.c   0%[                    ]       0  --.-KB/s               \rwinequality-white.c 100%[===================>] 258.23K  --.-KB/s    in 0.05s   \n",
            "\n",
            "2020-07-06 04:59:02 (4.93 MB/s) - ‘winequality-white.csv’ saved [264426/264426]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JRgNAt1hamha",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "41ef077f-2b98-43f6-f01e-76eeff58c26e"
      },
      "source": [
        "wine_path = 'winequality-white.csv'\n",
        "wineq_numpy = np.loadtxt(wine_path, dtype=np.float32, delimiter=';', skiprows=1)\n",
        "wineq_numpy"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 7.  ,  0.27,  0.36, ...,  0.45,  8.8 ,  6.  ],\n",
              "       [ 6.3 ,  0.3 ,  0.34, ...,  0.49,  9.5 ,  6.  ],\n",
              "       [ 8.1 ,  0.28,  0.4 , ...,  0.44, 10.1 ,  6.  ],\n",
              "       ...,\n",
              "       [ 6.5 ,  0.24,  0.19, ...,  0.46,  9.4 ,  6.  ],\n",
              "       [ 5.5 ,  0.29,  0.3 , ...,  0.38, 12.8 ,  7.  ],\n",
              "       [ 6.  ,  0.21,  0.38, ...,  0.32, 11.8 ,  6.  ]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dc-hL0vlgnHg",
        "colab_type": "text"
      },
      "source": [
        "Next, check that all the data has been read."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2tCmxL3gPAA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "3a276fd1-f062-4235-cbde-f2b5e6e6f310"
      },
      "source": [
        "col_list = next(csv.reader(open(wine_path), delimiter=';'))\n",
        "wineq_numpy.shape, col_list"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((4898, 12),\n",
              " ['fixed acidity',\n",
              "  'volatile acidity',\n",
              "  'citric acid',\n",
              "  'residual sugar',\n",
              "  'chlorides',\n",
              "  'free sulfur dioxide',\n",
              "  'total sulfur dioxide',\n",
              "  'density',\n",
              "  'pH',\n",
              "  'sulphates',\n",
              "  'alcohol',\n",
              "  'quality'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QeHB0evohOyx",
        "colab_type": "text"
      },
      "source": [
        "And now proceed to convert the NumPy array to a PyTorch tensor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvvwtuhMg-PB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "52a394f8-99c9-4751-840a-950cf43c27ab"
      },
      "source": [
        "wineq = torch.from_numpy(wineq_numpy)\n",
        "wineq.shape, wineq.type()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([4898, 12]), 'torch.FloatTensor')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5GnV2UMYhqWE",
        "colab_type": "text"
      },
      "source": [
        "At this point, you have a torch.FloatTensor containing all columns, including the last, which refers to the quality score."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PgaitCNHq_vd",
        "colab_type": "text"
      },
      "source": [
        "### Preparing training and testing set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S0yTO5GprEY4",
        "colab_type": "text"
      },
      "source": [
        "You could treat the score as a continuous variable, keep it as a real number, and perform a regression task, or treat it as a label and try to guess such label from the chemical analysis in a classification task. \n",
        "\n",
        "In both methods, you typically remove the score from the tensor of input data and keep it in a separate tensor, so that you can use the score as the ground truth without it being input to your model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qQH0sZU5hiMS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "fcf77770-63ab-4878-a020-337dd3d07372"
      },
      "source": [
        "# Select all rows and all columns except the last one\n",
        "data = wineq[:, :-1]\n",
        "data, data.shape"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[ 7.00,  0.27,  ...,  0.45,  8.80],\n",
              "         [ 6.30,  0.30,  ...,  0.49,  9.50],\n",
              "         ...,\n",
              "         [ 5.50,  0.29,  ...,  0.38, 12.80],\n",
              "         [ 6.00,  0.21,  ...,  0.32, 11.80]]), torch.Size([4898, 11]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NiUNJjVbk4kr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "4174fa24-9712-4ab1-efe3-99cde0108a02"
      },
      "source": [
        "# Select all rows and the last column\n",
        "target = wineq[:, -1]\n",
        "target, target.shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([6., 6.,  ..., 7., 6.]), torch.Size([4898]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m9DObdNzmP6i",
        "colab_type": "text"
      },
      "source": [
        "If you want to transform the target tensor in a tensor of labels, you have two options, depending on the strategy or how you want to use the categorical data.\n",
        "\n",
        "1. One option is to treat a label as an integer vector of scores\n",
        "2. The other approach is to build a one-hot encoding of the scores"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RbBf91ZxlaJo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "9b21895c-c03e-4691-ff2c-b700d07dec7a"
      },
      "source": [
        "target = wineq[:, -1].long()\n",
        "target"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([6, 6,  ..., 7, 6])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YsKz25rCmzpw",
        "colab_type": "text"
      },
      "source": [
        "If targets were string labels (such as wine color), assigning an integer number to each string would allow you to follow the same approach.\n",
        "\n",
        "The other approach is to build a one-hot encoding of the scores—that is, encode\n",
        "each of the ten scores in a vector of ten elements, with all elements set to zero but one, at a different index for each score. \n",
        "\n",
        "This way, a score of 1 could be mapped to the vector (1,0,0,0,0,0,0,0,0,0), a score of 5 to (0,0,0,0,1,0,0,0,0,0) and so on.\n",
        "\n",
        "**One-hot encoding is appropriate for quantitative scores when fractional values between integer scores (such as 2.4) make no sense for the application (when score is either this or that).**\n",
        "\n",
        "You can achieve one-hot encoding by using the scatter_ method, which fills the\n",
        "tensor with values from a source tensor along the indices provided as arguments."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fjrJXnTbmtbQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "0f2adef3-2f03-4087-8b4b-ad77d73929c0"
      },
      "source": [
        "target_onehot = torch.zeros(target.shape[0], 10)\n",
        "target_onehot.scatter_(1, target.unsqueeze(1), 1.0)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0.,  ..., 0., 0.],\n",
              "        [0., 0.,  ..., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0.,  ..., 0., 0.],\n",
              "        [0., 0.,  ..., 0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IGAx_l7joggm",
        "colab_type": "text"
      },
      "source": [
        "First, notice that its name ends with an underscore. This convention in PyTorch indicates that the method won’t return a new tensor but modify the tensor in place. The arguments for scatter_ are:\n",
        "\n",
        "* The dimension along which the following two arguments are specified\n",
        "* A column tensor indicating the indices of the elements to scatter\n",
        "* A tensor containing the elements to scatter or a single scalar to scatter (1,in this case)\n",
        "\n",
        "The second argument of scatter_, the index tensor, is required to have the same\n",
        "number of dimensions as the tensor you scatter into. Because target_onehot has two dimensions (4898x10), you need to add an extra dummy dimension to target by\n",
        "using unsqueeze:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6cylv6JNoFqh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "5321bae3-f447-4f31-8944-fabbf4265801"
      },
      "source": [
        "target_unsqueezed = target.unsqueeze(1)\n",
        "target_unsqueezed"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[6],\n",
              "        [6],\n",
              "        ...,\n",
              "        [7],\n",
              "        [6]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u7MeApBSp5aK",
        "colab_type": "text"
      },
      "source": [
        "The call to unsqueeze adds a singleton dimension, from a 1D tensor of 4898 elements to a 2D tensor of size (4898x1), without changing its contents.\n",
        "\n",
        "**PyTorch allows you to use class indices directly as targets while training neural networks. If you want to use the score as a categorical input to the network, however, you’d have to transform it to a one-hot encoded tensor.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pnJYKhtkqohJ",
        "colab_type": "text"
      },
      "source": [
        "### Data normalization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hTcDW_xlqrJx",
        "colab_type": "text"
      },
      "source": [
        "Now go back to your data tensor, containing the 11 variables associated with the\n",
        "chemical analysis. You can use the functions in the PyTorch Tensor API to manipulate your data in tensor form. \n",
        "\n",
        "First, obtain means and standard deviations for each column:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZgIdSHtjpm7I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "934665cc-863e-42e0-bf7a-4c68c09af216"
      },
      "source": [
        "data_mean = torch.mean(data, dim=0)  # mean\n",
        "data_mean"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([6.85e+00, 2.78e-01, 3.34e-01, 6.39e+00, 4.58e-02, 3.53e+01, 1.38e+02,\n",
              "        9.94e-01, 3.19e+00, 4.90e-01, 1.05e+01])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k6bOkVKegFH9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "625ff710-d707-4e15-b8c0-b7aabfc0ec15"
      },
      "source": [
        "data_var = torch.var(data, dim=0)  # variance\n",
        "data_var"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([7.12e-01, 1.02e-02, 1.46e-02, 2.57e+01, 4.77e-04, 2.89e+02, 1.81e+03,\n",
              "        8.95e-06, 2.28e-02, 1.30e-02, 1.51e+00])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "USsKzYSAgfnL",
        "colab_type": "text"
      },
      "source": [
        "In this case, dim=0 indicates that the reduction is performed along dimension 0. \n",
        "\n",
        "At this point, you can normalize the data by subtracting the mean and dividing by the standard deviation, which helps with the learning process."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c-tsNttygV_n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "af41c4f8-6543-4eab-8712-0f742634b233"
      },
      "source": [
        "data_normalized = (data - data_mean) / torch.sqrt(data_var)\n",
        "data_normalized"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1.72e-01, -8.18e-02,  ..., -3.49e-01, -1.39e+00],\n",
              "        [-6.57e-01,  2.16e-01,  ...,  1.35e-03, -8.24e-01],\n",
              "        ...,\n",
              "        [-1.61e+00,  1.17e-01,  ..., -9.63e-01,  1.86e+00],\n",
              "        [-1.01e+00, -6.77e-01,  ..., -1.49e+00,  1.04e+00]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GyocKtY_g11F",
        "colab_type": "text"
      },
      "source": [
        "Next, look at the data with an eye to finding an easy way to tell good and bad wines apart at a glance. \n",
        "\n",
        "First, use the torch.le function to determine which rows in target\n",
        "correspond to a score less than or equal to 3."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "spw5MZE2gtZH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "a42656bd-2743-40f7-a758-c49baa0daed9"
      },
      "source": [
        "bad_indexes = torch.le(target, 3)\n",
        "bad_indexes.shape, bad_indexes.dtype, bad_indexes.sum()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([4898]), torch.bool, tensor(20))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yj-lKfDMhUhq",
        "colab_type": "text"
      },
      "source": [
        "Note that only 20 of the bad_indexes entries are set to 1! \n",
        "\n",
        "**By leveraging a feature in PyTorch called advanced indexing, you can use a binary tensor to index the data tensor.**\n",
        "\n",
        "This tensor essentially filters data to be only items (or rows) that correspond to 1 in the indexing tensor. The bad_indexes tensor has the same shape as target, with a value of 0 or 1 depending on the outcome of the comparison between your threshold and each element in the original target tensor:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ewIzdZQhG8d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "d6bd31db-3c8a-469d-b739-01195910cd8e"
      },
      "source": [
        "bad_data = data[bad_indexes]\n",
        "bad_data.shape"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([20, 11])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DJ0NnwdUiBbn",
        "colab_type": "text"
      },
      "source": [
        "Note that the new bad_data tensor has 20 rows, the same as the number of rows with a 1 in the bad_indexes tensor. It retains all 11 columns.\n",
        "\n",
        "Now you can start to get information about wines grouped into good, middling,\n",
        "and bad categories. Take the .mean() of each column:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iiHxToz0hsjl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "99a78952-aff6-4ca3-cfc5-01a344088b1f"
      },
      "source": [
        "bad_data = data[torch.le(target, 3)]\n",
        "mid_data = data[torch.gt(target, 3) & torch.lt(target, 7)]\n",
        "good_data = data[torch.ge(target, 7)]\n",
        "\n",
        "bad_mean = torch.mean(bad_data, dim=0)\n",
        "mid_mean = torch.mean(mid_data, dim=0)\n",
        "good_mean = torch.mean(good_data, dim=0)\n",
        "\n",
        "for i, args in enumerate(zip(col_list, bad_mean, mid_mean, good_mean)):\n",
        "  print('{:2} {:20} {:6.2f} {:6.2f} {:6.2f}'.format(i, *args))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " 0 fixed acidity          7.60   6.89   6.73\n",
            " 1 volatile acidity       0.33   0.28   0.27\n",
            " 2 citric acid            0.34   0.34   0.33\n",
            " 3 residual sugar         6.39   6.71   5.26\n",
            " 4 chlorides              0.05   0.05   0.04\n",
            " 5 free sulfur dioxide   53.33  35.42  34.55\n",
            " 6 total sulfur dioxide 170.60 141.83 125.25\n",
            " 7 density                0.99   0.99   0.99\n",
            " 8 pH                     3.19   3.18   3.22\n",
            " 9 sulphates              0.47   0.49   0.50\n",
            "10 alcohol               10.34  10.26  11.42\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ECaA9tTPoKDB",
        "colab_type": "text"
      },
      "source": [
        "It looks as though you’re on to something here. At first glance, the bad wines seem to have higher total sulfur dioxide, among other differences. You could use a threshold on total sulfur dioxide as a crude criterion for discriminating good wines from bad ones. \n",
        "\n",
        "Now get the indexes in which the total sulfur dioxide column is below the midpoint you calculated earlier, like so:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-r52WlqjUKO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "70c26176-c35b-453b-ea76-f1b943637477"
      },
      "source": [
        "total_sulfur_threshold = 141.83\n",
        "total_sulfur_data = data[:, 6]\n",
        "predicted_indexes = torch.lt(total_sulfur_data, total_sulfur_threshold)\n",
        "predicted_indexes.shape, predicted_indexes.dtype, predicted_indexes.sum()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([4898]), torch.bool, tensor(2727))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2B56urbqpyXs",
        "colab_type": "text"
      },
      "source": [
        "Your threshold implies that slightly more than half of the wines are going to be high-quality.\n",
        "\n",
        "Next, you need to get the indexes of the good wines:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FOqxdqU5ppB0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "445878fa-0b5c-4e82-bee5-36cc0918dce7"
      },
      "source": [
        "actual_indexes = torch.gt(target, 5)\n",
        "actual_indexes.shape, actual_indexes.dtype, actual_indexes.sum()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([4898]), torch.bool, tensor(3258))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MLengN7aqQeH",
        "colab_type": "text"
      },
      "source": [
        "Because you have about 500 more good wines than your threshold predicted, you\n",
        "already have hard evidence that the threshold isn’t perfect.\n",
        "\n",
        "Now you need to see how well your predictions line up with the actual rankings.\n",
        "Perform a logical and between your prediction indexes and the good indexes\n",
        "(remembering that each index is an array of 0s and 1s), and use that intersection of wines in agreement to determine how well you did:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OEKJFoWhqD6Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "ce3e53a3-c494-4e74-fa30-50fda100b296"
      },
      "source": [
        "n_matches = torch.sum(actual_indexes & predicted_indexes).item()\n",
        "n_predicted = torch.sum(predicted_indexes).item()\n",
        "n_actual = torch.sum(actual_indexes).item()\n",
        "\n",
        "n_matches, n_matches / n_predicted, n_matches / n_actual"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2018, 0.74000733406674, 0.6193984039287906)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_IqOaDvprJ-4",
        "colab_type": "text"
      },
      "source": [
        "You got around 2,000 wines right! Because you had 2,700 wines predicted, a 74 percent chance exists that if you predict a wine to be high-quality, it is. \n",
        "\n",
        "Unfortunately, you have 3,200 good wines and identified only 61 percent of them. Well, we guess you got what you signed up for; that result is barely better than random.\n",
        "\n",
        "**This example is naïve, of course. You know for sure that multiple variables contribute to wine quality and that the relationships between the values of these variables and the outcome (which could be the actual score rather than a binarized version of it) is likely to be more complicated than a simple threshold on a single value.**\n",
        "\n",
        "**Indeed, a simple neural network would overcome all these limitations, as would a lot of other basic machine learning methods.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xPf-7yMPrxA4",
        "colab_type": "text"
      },
      "source": [
        "## Time series"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4eMG52QNrz25",
        "colab_type": "text"
      },
      "source": [
        "In the preceding section, we covered how to represent data organized in a flat table. As we noted, every row in the table was independent from the others; their order did not matter. Equivalently, no column encoded information on what rows came before and what rows came after.\n",
        "\n",
        "Going back to the wine data set, you could have had a Year column that allowed you to look at how wine quality evolved year over year. (Unfortunately, we don’t have such data at hand, but we’re working hard on collecting the data samples manually, bottle by bottle.)\n",
        "\n",
        "In the meantime, we’ll switch to another interesting data set: data from a Washington, D.C., bike sharing system reporting the hourly count of rental bikes between 2011 and 2012 in the Capital bike-share system with the corresponding weather and seasonal information.\n",
        "\n",
        "**The goal is to take a flat 2D data set and transform it into a 3D one.**\n",
        "\n",
        "<img src='https://github.com/rahiakela/img-repo/blob/master/deep-learning-with-pytorch/time-series.png?raw=1' width='800'/>\n",
        "\n",
        "> Transforming a 1D multichannel data set into a 2D multichannel data set by separating the date and hour of each sample into separate axes.\n",
        "\n",
        "In the source data, each row is a separate hour of data. We want to change the row-per-hour organization so that you have one axis that increases at a rate of one day per index increment and another axis that represents hour of day (independent of the date). The third axis is different columns of data (weather, temperature, and so on)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xpo5uxcuP868",
        "colab_type": "text"
      },
      "source": [
        "### Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JH-Jok5Eq53R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "4f7cca32-5082-4a75-decb-3d4b338b2197"
      },
      "source": [
        "! wget https://raw.githubusercontent.com/deep-learning-with-pytorch/dlwpt-code/master/data/p1ch4/bike-sharing-dataset/hour-fixed.csv"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-07-06 04:59:10--  https://raw.githubusercontent.com/deep-learning-with-pytorch/dlwpt-code/master/data/p1ch4/bike-sharing-dataset/hour-fixed.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1148001 (1.1M) [text/plain]\n",
            "Saving to: ‘hour-fixed.csv’\n",
            "\n",
            "\rhour-fixed.csv        0%[                    ]       0  --.-KB/s               \rhour-fixed.csv      100%[===================>]   1.09M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2020-07-06 04:59:10 (10.7 MB/s) - ‘hour-fixed.csv’ saved [1148001/1148001]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ZYw2UdPQSiQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "3c39c55d-6e3a-4889-aa94-f186d2944dba"
      },
      "source": [
        "# load csv file and convert date strings to numbers corresponding to the day of the month in column 1.\n",
        "bikes_numpy = np.loadtxt('hour-fixed.csv', dtype=np.float32, delimiter=',', skiprows=1, converters={1: lambda x: float(x[8:10])})\n",
        "bikes = torch.from_numpy(bikes_numpy)\n",
        "bikes"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.00e+00, 1.00e+00,  ..., 1.30e+01, 1.60e+01],\n",
              "        [2.00e+00, 1.00e+00,  ..., 3.20e+01, 4.00e+01],\n",
              "        ...,\n",
              "        [1.74e+04, 3.10e+01,  ..., 4.80e+01, 6.10e+01],\n",
              "        [1.74e+04, 3.10e+01,  ..., 3.70e+01, 4.90e+01]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7m64VhDeYhVM",
        "colab_type": "text"
      },
      "source": [
        "For every hour, the data set reports the following variables:\n",
        "\n",
        "```python\n",
        "instant         # index of record\n",
        "day             # day of month\n",
        "season          # season (1: spring, 2: summer, 3: fall, 4: winter)\n",
        "yr              # year (0: 2011, 1: 2012)\n",
        "mnth            # month (1 to 12)\n",
        "hr              # hour (0 to 23)\n",
        "holiday         # holiday status\n",
        "weekday         # day of the week\n",
        "workingday      # working day status\n",
        "weathersit      # weather situation\n",
        "                # (1: clear, 2:mist, 3: light rain/snow, 4: heavy rain/snow)\n",
        "temp            # temperature in C\n",
        "atemp           # perceived temperature in C\n",
        "hum             # humidity\n",
        "windspeed       # windspeed\n",
        "casual          # number of causal users\n",
        "registered      # number of registered users\n",
        "cnt             # count of rental bikes\n",
        "```\n",
        "In a time-series data set such as this one, rows represent successive time points: a dimension along which they’re ordered. Sure, you could treat each row as independent and try to predict the number of circulating bikes based on, say, a particular time of day regardless of what happened earlier.\n",
        "\n",
        "This existence of an ordering, however, gives you the opportunity to exploit causal relationships across time. You can predict bike rides at one time based on the fact that it was raining at an earlier time, for example. For the time being, you’re going to focus on learning how to turn your bike-sharing data set into something that your neural network can ingest in fixed-size chunks.\n",
        "\n",
        "Now go back to your bike-sharing data set. The first column is the index (the\n",
        "global ordering of the data); the second is the date; the sixth is the time of day. You have everything you need to create a data set of daily sequences of ride counts and other exogenous variables. Your data set is already sorted, but if it weren’t, you could use torch.sort on it to order it appropriately.\n",
        "\n",
        "All you have to do to obtain your daily hours data set is view the same tensor in batches of 24 hours. \n",
        "\n",
        "Take a look at the shape and strides of your bikes tensor:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RsS_5Tv1YEZv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7612312a-90d8-4b1e-d880-65121b7e3ab6"
      },
      "source": [
        "bikes.shape, bikes.stride()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([17520, 17]), (17, 1))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LJXyMS73az6I",
        "colab_type": "text"
      },
      "source": [
        "That’s 17,520 hours, 17 columns. Now reshape the data to have three axes (day, hour, and then your 17 columns):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_y0dyi0naYIS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "751f5492-d96a-4eee-d857-85c8bb41e9b7"
      },
      "source": [
        "daily_bikes = bikes.view(-1, 24, bikes.shape[1])\n",
        "daily_bikes.shape, daily_bikes.stride()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([730, 24, 17]), (408, 17, 1))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Gn45f1ZbfjH",
        "colab_type": "text"
      },
      "source": [
        "What happened here? First, the bikes.shape[1] is 17, which is the number of columns in the bikes tensor. \n",
        "\n",
        "But the real crux of the code is the call to view, which is important: it changes the way that the tensor looks at the same data as contained in storage.\n",
        "\n",
        "**Calling view on a tensor returns a new tensor that changes the number of dimensions and the striding information without changing the storage.** As a result, you can rearrange your tensor at zero cost because no data is copied at all. Your call to view requires you to provide the new shape for the returned tensor. **Use the -1 as a placeholder for \"however many indexes are left, given the other dimensions and the original number of elements.\"**\n",
        "\n",
        "**Remember that Storage is a contiguous, linear container for numbers—floatingpoint, in this case. Your bikes tensor has rows stored one after the other in corresponding storage, as confirmed by the output from the call to bikes.stride() earlier.**\n",
        "\n",
        "The rightmost dimension is the number of columns in the original data set. In the middle dimension, you have time split into chunks of 24 sequential hours. \n",
        "\n",
        "In other words, you now have N sequences of L hours in a day for C channels. \n",
        "\n",
        "To get to your desired NxCxL ordering, you need to transpose the tensor:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oxEDdCDwbAmM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f9f243a5-6a12-4555-ca1d-a9b63abff626"
      },
      "source": [
        "daily_bikes = daily_bikes.transpose(1, 2)\n",
        "daily_bikes.shape, daily_bikes.stride()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([730, 17, 24]), (408, 1, 17))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qb11_H_dgG4t",
        "colab_type": "text"
      },
      "source": [
        "We mentioned earlier that the weather-situation variable is ordinal. In fact, it has 4 levels: 1 for the best weather and 4 for the worst. You could treat this variable as categorical, with levels interpreted as labels, or continuous. \n",
        "\n",
        "If you choose categorical, you turn the variable into a one-hot encoded vector and concatenate the columns with the data set. To make rendering your data easier, limit yourself to the first day for now. \n",
        "\n",
        "First, initialize a zero-filled matrix with a number of rows equal to the number of hours in the day and a number of columns equal to the number of weather levels:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3XONIGrDdKFk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8907585f-3262-4b71-9045-c33b8180c771"
      },
      "source": [
        "first_day = bikes[:24].long()\n",
        "weather_onehot = torch.zeros(first_day.shape[0], 4)\n",
        "first_day[:, 9]"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 3, 3, 2, 2, 2, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aumHo0HEhb8_",
        "colab_type": "text"
      },
      "source": [
        "Then scatter ones into our matrix according to the corresponding level at each row. \n",
        "\n",
        "Remember the use of unsqueeze to add a singleton dimension earlier:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Js05QXcsg7_Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "79c43a77-713d-401f-e3b2-a8ec96e33fcc"
      },
      "source": [
        "# decreasing the values by 1 because the weather situation ranges from 1 to 4, whereas indices are 0-based.\n",
        "weather_onehot.scatter_(dim=1, index=first_day[:, 9].unsqueeze(1) -1, value=1.0)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 0., 0., 0.],\n",
              "        [1., 0., 0., 0.],\n",
              "        [1., 0., 0., 0.],\n",
              "        [1., 0., 0., 0.],\n",
              "        [1., 0., 0., 0.],\n",
              "        [0., 1., 0., 0.],\n",
              "        [1., 0., 0., 0.],\n",
              "        [1., 0., 0., 0.],\n",
              "        [1., 0., 0., 0.],\n",
              "        [1., 0., 0., 0.],\n",
              "        [1., 0., 0., 0.],\n",
              "        [1., 0., 0., 0.],\n",
              "        [1., 0., 0., 0.],\n",
              "        [0., 1., 0., 0.],\n",
              "        [0., 1., 0., 0.],\n",
              "        [0., 1., 0., 0.],\n",
              "        [0., 1., 0., 0.],\n",
              "        [0., 1., 0., 0.],\n",
              "        [0., 0., 1., 0.],\n",
              "        [0., 0., 1., 0.],\n",
              "        [0., 1., 0., 0.],\n",
              "        [0., 1., 0., 0.],\n",
              "        [0., 1., 0., 0.],\n",
              "        [0., 1., 0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MAI5dXwQiMRL",
        "colab_type": "text"
      },
      "source": [
        "The day started with weather 1 and ended with 2, so that seems right.\n",
        "\n",
        "Last, concatenate your matrix to your original data set, using the cat function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oONUl1gCiED-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "07b95059-5de2-49b9-b902-16a6c3159b9f"
      },
      "source": [
        "torch.cat((bikes[:24], weather_onehot), 1)[:1]"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1.00,  1.00,  1.00,  0.00,  1.00,  0.00,  0.00,  6.00,  0.00,  1.00,\n",
              "          0.24,  0.29,  0.81,  0.00,  3.00, 13.00, 16.00,  1.00,  0.00,  0.00,\n",
              "          0.00]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zO11RfTVlKmp",
        "colab_type": "text"
      },
      "source": [
        "For cat to succeed, the tensors must have the same size along the other dimensions (the row dimension, in this case).\n",
        "\n",
        "Note that your new last four columns are 1, 0, 0, 0—exactly what you’d expect\n",
        "with a weather value of 1.\n",
        "\n",
        "You could have done the same thing with the reshaped daily_bikes tensor.\n",
        "Remember that it’s shaped (B, C, L), where L = 24. \n",
        "\n",
        "First, create the zero tensor, with the same B and L but with the number of additional columns as C:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQlmtb43ifOb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "acbd34f2-664e-4748-f294-61ecad3d4284"
      },
      "source": [
        "daily_weather_onehot = torch.zeros(daily_bikes.shape[0], 4, daily_bikes.shape[2])\n",
        "daily_weather_onehot.shape"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([730, 4, 24])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CtsoAYuIl347",
        "colab_type": "text"
      },
      "source": [
        "Then scatter the one-hot encoding into the tensor in the C dimension. Because operation is performed in place, only the content of the tensor changes:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fSHIxnsflyVR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "64fca5e3-bb2a-4dde-a573-8b8bbad02558"
      },
      "source": [
        "daily_weather_onehot.scatter_(1, daily_bikes[:, 9, :].long().unsqueeze(1) - 1, 1.0)\n",
        "daily_weather_onehot.shape"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([730, 4, 24])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R_GfVqfrmZkK",
        "colab_type": "text"
      },
      "source": [
        "Concatenate along the C dimension:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YfvvSxFemSI6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "daily_bikes = torch.cat((daily_bikes, daily_weather_onehot), dim=1)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jlAafCGOmtHy",
        "colab_type": "text"
      },
      "source": [
        "We mentioned earlier that this method isn’t the only way to treat the weather-situation variable. Indeed, its labels have an ordinal relationship, so you could pretend that they’re special values of a continuous variable. You might transform the variable so that it runs from 0.0 to 1.0:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tqcvQ5RDmsc2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "daily_bikes[:, 9, :] = (daily_bikes[:, 9, :] - 1.0) / 3.0"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DJOsw-bdnYmY",
        "colab_type": "text"
      },
      "source": [
        "As we mention, rescaling variables to the [0.0, 1.0] interval or the [-1.0, 1.0] interval is something that you’ll want to do for all quantitative variables,\n",
        "such as temperature (column 10 in your data set). You’ll see why later; for now, we’ll say that it’s beneficial to the training process.\n",
        "\n",
        "You have multiple possibilities for rescaling variables. You can map their range to [0.0, 1.0]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6qfLsU50nCca",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "outputId": "be69f597-162c-4e31-a4ac-a6194a45fda4"
      },
      "source": [
        "temp = daily_bikes[:, 10, :]\n",
        "temp_min = torch.min(temp)\n",
        "temp_max = torch.max(temp)\n",
        "daily_bikes[:, 10, :] = (daily_bikes[:, 10, :] - temp_min) / (temp_max - temp_min)\n",
        "daily_bikes"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[1.00e+00, 2.00e+00,  ..., 2.30e+01, 2.40e+01],\n",
              "         [1.00e+00, 1.00e+00,  ..., 1.00e+00, 1.00e+00],\n",
              "         ...,\n",
              "         [0.00e+00, 0.00e+00,  ..., 0.00e+00, 0.00e+00],\n",
              "         [0.00e+00, 0.00e+00,  ..., 0.00e+00, 0.00e+00]],\n",
              "\n",
              "        [[2.50e+01, 2.60e+01,  ..., 4.60e+01, 4.70e+01],\n",
              "         [2.00e+00, 2.00e+00,  ..., 2.00e+00, 2.00e+00],\n",
              "         ...,\n",
              "         [0.00e+00, 0.00e+00,  ..., 0.00e+00, 0.00e+00],\n",
              "         [0.00e+00, 0.00e+00,  ..., 0.00e+00, 0.00e+00]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[1.73e+04, 1.73e+04,  ..., 1.74e+04, 1.74e+04],\n",
              "         [3.00e+01, 3.00e+01,  ..., 3.00e+01, 3.00e+01],\n",
              "         ...,\n",
              "         [0.00e+00, 0.00e+00,  ..., 0.00e+00, 0.00e+00],\n",
              "         [0.00e+00, 0.00e+00,  ..., 0.00e+00, 0.00e+00]],\n",
              "\n",
              "        [[1.74e+04, 1.74e+04,  ..., 1.74e+04, 1.74e+04],\n",
              "         [3.10e+01, 3.10e+01,  ..., 3.10e+01, 3.10e+01],\n",
              "         ...,\n",
              "         [0.00e+00, 0.00e+00,  ..., 0.00e+00, 0.00e+00],\n",
              "         [0.00e+00, 0.00e+00,  ..., 0.00e+00, 0.00e+00]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cEUSwxYetDhs",
        "colab_type": "text"
      },
      "source": [
        "or subtract the mean and divide by the standard deviation:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UbaPKzdXoHQf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "outputId": "846bab34-b288-4551-8122-155586f908ff"
      },
      "source": [
        "temp = daily_bikes[:, 10, :]\n",
        "daily_bikes[:, 10, :] = (daily_bikes[:, 10, :] - torch.mean(temp)) / torch.std(temp)\n",
        "daily_bikes"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[1.00e+00, 2.00e+00,  ..., 2.30e+01, 2.40e+01],\n",
              "         [1.00e+00, 1.00e+00,  ..., 1.00e+00, 1.00e+00],\n",
              "         ...,\n",
              "         [0.00e+00, 0.00e+00,  ..., 0.00e+00, 0.00e+00],\n",
              "         [0.00e+00, 0.00e+00,  ..., 0.00e+00, 0.00e+00]],\n",
              "\n",
              "        [[2.50e+01, 2.60e+01,  ..., 4.60e+01, 4.70e+01],\n",
              "         [2.00e+00, 2.00e+00,  ..., 2.00e+00, 2.00e+00],\n",
              "         ...,\n",
              "         [0.00e+00, 0.00e+00,  ..., 0.00e+00, 0.00e+00],\n",
              "         [0.00e+00, 0.00e+00,  ..., 0.00e+00, 0.00e+00]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[1.73e+04, 1.73e+04,  ..., 1.74e+04, 1.74e+04],\n",
              "         [3.00e+01, 3.00e+01,  ..., 3.00e+01, 3.00e+01],\n",
              "         ...,\n",
              "         [0.00e+00, 0.00e+00,  ..., 0.00e+00, 0.00e+00],\n",
              "         [0.00e+00, 0.00e+00,  ..., 0.00e+00, 0.00e+00]],\n",
              "\n",
              "        [[1.74e+04, 1.74e+04,  ..., 1.74e+04, 1.74e+04],\n",
              "         [3.10e+01, 3.10e+01,  ..., 3.10e+01, 3.10e+01],\n",
              "         ...,\n",
              "         [0.00e+00, 0.00e+00,  ..., 0.00e+00, 0.00e+00],\n",
              "         [0.00e+00, 0.00e+00,  ..., 0.00e+00, 0.00e+00]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b5CX3h51tmFz",
        "colab_type": "text"
      },
      "source": [
        "In this latter case, the variable has zero mean and unitary standard deviation. If the variable were drawn from a Gaussian distribution, 68 percent of the samples would sit in the [-1.0, 1.0] interval.\n",
        "\n",
        "Great—you’ve built another nice data set that you’ll get to use later. For now, it’s important only that you got an idea of how a time series is laid out and how you can wrangle the data into a form that a network will digest.\n",
        "\n",
        "**Other kinds of data look like a time series, in that strict ordering exists. The top two in that category are text and audio.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nbB3HgIxt939",
        "colab_type": "text"
      },
      "source": [
        "## Text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cjU839AGt-59",
        "colab_type": "text"
      },
      "source": [
        "Deep learning has taken the field of natural language processing (NLP) by storm, particularly by using models that repeatedly consume a combination of new input and previous model output. These models are called recurrent neural networks, and they’ve been applied with great success to text categorization, text generation, and automated translation systems.\n",
        "\n",
        "Networks operate on text at two levels: at character level, by processing one character at a time, and at word level, in which individual words are the finest-grained entities seen by the network. The technique you use to encode text information into tensor form is the same whether you operate at character level or at word level. This technique is nothing magic; you stumbled upon it earlier. It’s one-hot encoding.\n",
        "\n",
        "Let's load Jane Austen’s Pride and Prejudice from the Project Gutenberg website."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ow8l0bWytcG3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "fd3bafbb-118b-479b-fa0b-a97573b2c66e"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/deep-learning-with-pytorch/dlwpt-code/master/data/p1ch4/jane-austen/1342-0.txt"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-07-06 05:44:47--  https://raw.githubusercontent.com/deep-learning-with-pytorch/dlwpt-code/master/data/p1ch4/jane-austen/1342-0.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 711298 (695K) [text/plain]\n",
            "Saving to: ‘1342-0.txt’\n",
            "\n",
            "\r1342-0.txt            0%[                    ]       0  --.-KB/s               \r1342-0.txt          100%[===================>] 694.63K  --.-KB/s    in 0.1s    \n",
            "\n",
            "2020-07-06 05:44:47 (6.51 MB/s) - ‘1342-0.txt’ saved [711298/711298]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RCW3tABpnRS3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('1342-0.txt', encoding='utf8') as f:\n",
        "  text = f.read()"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4wYkHVgppVyt",
        "colab_type": "text"
      },
      "source": [
        "At this point, you need to parse the characters in the text and provide a one-hot encoding for each of them. Each character will be represented by a vector of length equal to the number of characters in the encoding. This vector will contain all zeros except for a 1 at the index corresponding to the location of the character in the encoding.\n",
        "\n",
        "First, split your text into a list of lines and pick an arbitrary line to focus on:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7CRdnI3oV5_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e4556024-887b-435d-e5fb-5927a446ecb1"
      },
      "source": [
        "lines = text.split('\\n')\n",
        "line = lines[200]\n",
        "line"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'“Impossible, Mr. Bennet, impossible, when I am not acquainted with him'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E8iDptjbqGeC",
        "colab_type": "text"
      },
      "source": [
        "Create a tensor that can hold the total number of one-hot encoded characters for the whole line:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y82DRsxNpmqb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "26ea906e-963e-41cf-d234-49d89be6fdaa"
      },
      "source": [
        "# 128 hardcoded due to the limits of ASCII\n",
        "letter_tensor = torch.zeros(len(line), 128)\n",
        "letter_tensor.shape"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([70, 128])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ahG0dhrUqpYK",
        "colab_type": "text"
      },
      "source": [
        "Note that letter_tensor holds a one-hot encoded character per row. Now set a 1 on each row in the right position so that each row represents the right character. \n",
        "\n",
        "The index where the 1 has to be set corresponds to the index of the character in the encoding:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YOElsBPZqXpS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The text uses directional double quotes, which aren’t valid ASCII, so screen them out here.\n",
        "for i, letter in enumerate(line.lower().strip()):\n",
        "  letter_index = ord(letter) if ord(letter) < 128 else 0\n",
        "  letter_tensor[i][letter_index] = 1"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZX4ipB_JrxPl",
        "colab_type": "text"
      },
      "source": [
        "You’ve one-hot encoded your sentence into a representation that a neural network\n",
        "can digest. You could do word-level encoding the same way by establishing a vocabulary and one-hot encoding sentences, sequences of words, along the rows of your tensor. Because a vocabulary contains many words, this method produces wide encoded vectors that may not be practical.\n",
        "\n",
        "Let's define clean_words, which takes text and returns it lowercase and stripped of punctuation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-8RwfRCrTcA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clean_words(input_str):\n",
        "  punctuation = '.,;:\"!?”“_-'\n",
        "  word_list = input_str.lower().replace('\\n', ' ').split()\n",
        "  word_list = [word.strip(punctuation) for word in word_list]\n",
        "  return word_list"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qEr6Dacpuzd0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "4ea1df64-c1a7-43e6-9c1b-988e16ef76f9"
      },
      "source": [
        "words_in_line = clean_words(line)\n",
        "line, words_in_line"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('“Impossible, Mr. Bennet, impossible, when I am not acquainted with him',\n",
              " ['impossible',\n",
              "  'mr',\n",
              "  'bennet',\n",
              "  'impossible',\n",
              "  'when',\n",
              "  'i',\n",
              "  'am',\n",
              "  'not',\n",
              "  'acquainted',\n",
              "  'with',\n",
              "  'him'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nFtxzvKfvDGL",
        "colab_type": "text"
      },
      "source": [
        "Next, build a mapping of words to indexes in your encoding:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CccPiOY-u625",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "669f5f00-c59c-42da-bac2-c9c36faeae34"
      },
      "source": [
        "word_list = sorted(set(clean_words(text)))\n",
        "word2index_dict = {word: i for (i, word) in enumerate(word_list)}\n",
        "\n",
        "len(word2index_dict), word2index_dict['impossible']"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7261, 3394)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jiHZxwOBw2Ez",
        "colab_type": "text"
      },
      "source": [
        "Note that all_words is now a dictionary with words as keys and an integer as value. You’ll use this dictionary to efficiently find the index of a word as you one-hot encode it.\n",
        "\n",
        "Now focus on your sentence. Break it into words and one-hot encode it—that is,\n",
        "populate a tensor with one one-hot encoded vector per word. Create an empty vector, and assign the one-hot encoded values of the word in the sentence."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3vPMWP3jwsqD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "8327c177-1e76-40b3-e6b9-f33e841b401d"
      },
      "source": [
        "word_tensor = torch.zeros(len(words_in_line), len(word2index_dict))\n",
        "for i, word in enumerate(words_in_line):\n",
        "  word_index = word2index_dict[word]\n",
        "  word_tensor[i][word_index] = 1\n",
        "  print('{:2} {:4} {}'.format(i, word_index, word))\n",
        "\n",
        "print(word_tensor.shape)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " 0 3394 impossible\n",
            " 1 4305 mr\n",
            " 2  813 bennet\n",
            " 3 3394 impossible\n",
            " 4 7078 when\n",
            " 5 3315 i\n",
            " 6  415 am\n",
            " 7 4436 not\n",
            " 8  239 acquainted\n",
            " 9 7148 with\n",
            "10 3215 him\n",
            "torch.Size([11, 7261])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xCL6xQXNx60P",
        "colab_type": "text"
      },
      "source": [
        "At this point, tensor represents one sentence of length 11 in an encoding space of size 7261—the number of words in your dictionary."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gd3kyM2Rx8_q",
        "colab_type": "text"
      },
      "source": [
        "## Images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eoWbesIFxrv0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}