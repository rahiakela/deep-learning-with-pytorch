{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "real-world-data-representation-with-tensors.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP3m01Qo7pvZBIn+9hoQMDC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahiakela/deep-learning-with-pytorch/blob/4-real-world-data-representation-with-tensors/real_world_data_representation_with_tensors.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YprFwmUzY0s_",
        "colab_type": "text"
      },
      "source": [
        "# Real-world data representation with tensors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kFTuRDLTZA0H",
        "colab_type": "text"
      },
      "source": [
        "Tensors are the building blocks for data in PyTorch. Neural networks take tensors in input and produce tensors as outputs. In fact, all operations within a neural network and during optimization are operations between tensors, and all parameters (such as weights and biases) in a neural network are tensors. Having a good sense of how to perform operations on tensors and index them effectively is central to using tools like PyTorch successfully.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JbLJnzouZTWq",
        "colab_type": "text"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PgKeZjTjZU3o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! pip install torch==1.5.0+cpu torchvision==0.6.0+cpu -f https://download.pytorch.org/whl/torch_stable.html"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vj5XF2J-ZfEW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import csv"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W9twn_K1oNhw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.set_printoptions(edgeitems=2, precision=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n-eh5hVNZk8W",
        "colab_type": "text"
      },
      "source": [
        "## Tabular data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Suf97x-IZmWb",
        "colab_type": "text"
      },
      "source": [
        "The simplest form of data you’ll encounter in your machine learning job is sitting in a spreadsheet, in a CSV (comma-separated values) file, or in a database. Whatever the medium, this data is a table containing one row per sample (or record), in which columns contain one piece of information about the sample.\n",
        "\n",
        "Columns may contain numerical values, such as temperatures at specific locations, or labels, such as a string expressing an attribute of the sample (like \"blue\"). **Therefore, tabular data typically isn’t homogeneous; different columns don’t have the same type.** You might have a column showing the weight of apples and another encoding their color in a label.\n",
        "\n",
        "PyTorch tensors, on the other hand, are homogeneous. Other data science packages, such as Pandas, have the concept of the data frame, an object representing a data set with named, heterogenous columns. By contrast, information in PyTorch is encoded as a number, typically floating-point (though integer types are supported as well).\n",
        "\n",
        "Numeric encoding is deliberate, because neural networks are mathematical entities that take real numbers as inputs and produce real numbers as output through successive application of matrix multiplications and nonlinear functions.\n",
        "\n",
        "**Your first job as a deep learning practitioner, therefore, is to encode heterogenous, real-world data in a tensor of floating-point numbers, ready for consumption by a neural network.**\n",
        "\n",
        "We start with something fun: wine. The Wine Quality data set is a freely available table containing chemical characterizations of samples of vinho verde (a wine from northern Portugal) together with a sensory quality score. You can download the data set for white wines at https://archive.ics.uci.edu/ml/machine-learning-databases/winequality/winequality-white.csv.\n",
        "\n",
        "<img src='https://github.com/rahiakela/img-repo/blob/master/deep-learning-with-pytorch/wine-datasets.png?raw=1' width='800'/>\n",
        "\n",
        "You hope to find a relationship between one of the chemical\n",
        "columns in your data and the quality column. Here, you’re expecting to see quality increase as sulfur decreases.\n",
        "\n",
        "Before you can get to that observation, however, you need to be able to examine\n",
        "the data in a more usable way than opening the file in a text editor. We’ll show you how to load the data by using Python and then turn it into a PyTorch tensor."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K06FFj1nqwqm",
        "colab_type": "text"
      },
      "source": [
        "### Loading dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tm8Z1t0QqzPh",
        "colab_type": "text"
      },
      "source": [
        "Python offers several options for loading a CSV file quickly. Three popular options are:\n",
        "\n",
        "* The csv module that ships with Python\n",
        "* NumPy\n",
        "* Pandas\n",
        "\n",
        "The third option is the most time- and memory-efficient, but we’ll avoid introducing an additional library into your learning trajectory merely to load a file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_PFNWCa2rllI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "fa9fd993-8f86-400c-f2aa-e5b43629672e"
      },
      "source": [
        "! wget https://github.com/deep-learning-with-pytorch/dlwpt-code/tree/master/data/p1ch4/tabular-wine/winequality-white.csv"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-06-08 06:47:35--  https://github.com/deep-learning-with-pytorch/dlwpt-code/tree/master/data/p1ch4/tabular-wine/winequality-white.csv\n",
            "Resolving github.com (github.com)... 140.82.113.4\n",
            "Connecting to github.com (github.com)|140.82.113.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://github.com/deep-learning-with-pytorch/dlwpt-code/blob/master/data/p1ch4/tabular-wine/winequality-white.csv [following]\n",
            "--2020-06-08 06:47:36--  https://github.com/deep-learning-with-pytorch/dlwpt-code/blob/master/data/p1ch4/tabular-wine/winequality-white.csv\n",
            "Reusing existing connection to github.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘winequality-white.csv.1’\n",
            "\n",
            "winequality-white.c     [   <=>              ]   1.18M  2.44MB/s    in 0.5s    \n",
            "\n",
            "2020-06-08 06:47:36 (2.44 MB/s) - ‘winequality-white.csv.1’ saved [1234214]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JRgNAt1hamha",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "fc4713aa-a356-4bb7-c694-39824010c8be"
      },
      "source": [
        "wine_path = 'winequality-white.csv'\n",
        "wineq_numpy = np.loadtxt(wine_path, dtype=np.float32, delimiter=';', skiprows=1)\n",
        "wineq_numpy"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 7.  ,  0.27,  0.36, ...,  0.45,  8.8 ,  6.  ],\n",
              "       [ 6.3 ,  0.3 ,  0.34, ...,  0.49,  9.5 ,  6.  ],\n",
              "       [ 8.1 ,  0.28,  0.4 , ...,  0.44, 10.1 ,  6.  ],\n",
              "       ...,\n",
              "       [ 6.5 ,  0.24,  0.19, ...,  0.46,  9.4 ,  6.  ],\n",
              "       [ 5.5 ,  0.29,  0.3 , ...,  0.38, 12.8 ,  7.  ],\n",
              "       [ 6.  ,  0.21,  0.38, ...,  0.32, 11.8 ,  6.  ]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dc-hL0vlgnHg",
        "colab_type": "text"
      },
      "source": [
        "Next, check that all the data has been read."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2tCmxL3gPAA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "72986358-7a36-4df0-d85b-7bb7560d9bb7"
      },
      "source": [
        "col_list = next(csv.reader(open(wine_path), delimiter=';'))\n",
        "wineq_numpy.shape, col_list"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((4898, 12),\n",
              " ['fixed acidity',\n",
              "  'volatile acidity',\n",
              "  'citric acid',\n",
              "  'residual sugar',\n",
              "  'chlorides',\n",
              "  'free sulfur dioxide',\n",
              "  'total sulfur dioxide',\n",
              "  'density',\n",
              "  'pH',\n",
              "  'sulphates',\n",
              "  'alcohol',\n",
              "  'quality'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QeHB0evohOyx",
        "colab_type": "text"
      },
      "source": [
        "And now proceed to convert the NumPy array to a PyTorch tensor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvvwtuhMg-PB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "71f05a06-5396-44fa-8b82-5e3384eaddd3"
      },
      "source": [
        "wineq = torch.from_numpy(wineq_numpy)\n",
        "wineq.shape, wineq.type()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([4898, 12]), 'torch.FloatTensor')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5GnV2UMYhqWE",
        "colab_type": "text"
      },
      "source": [
        "At this point, you have a torch.FloatTensor containing all columns, including the last, which refers to the quality score."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PgaitCNHq_vd",
        "colab_type": "text"
      },
      "source": [
        "### Preparing training and testing set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S0yTO5GprEY4",
        "colab_type": "text"
      },
      "source": [
        "You could treat the score as a continuous variable, keep it as a real number, and perform a regression task, or treat it as a label and try to guess such label from the chemical analysis in a classification task. \n",
        "\n",
        "In both methods, you typically remove the score from the tensor of input data and keep it in a separate tensor, so that you can use the score as the ground truth without it being input to your model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qQH0sZU5hiMS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "4acd0623-e025-4c94-9031-e151a525a62f"
      },
      "source": [
        "# Select all rows and all columns except the last one\n",
        "data = wineq[:, :-1]\n",
        "data, data.shape"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[ 7.0000,  0.2700,  0.3600,  ...,  3.0000,  0.4500,  8.8000],\n",
              "         [ 6.3000,  0.3000,  0.3400,  ...,  3.3000,  0.4900,  9.5000],\n",
              "         [ 8.1000,  0.2800,  0.4000,  ...,  3.2600,  0.4400, 10.1000],\n",
              "         ...,\n",
              "         [ 6.5000,  0.2400,  0.1900,  ...,  2.9900,  0.4600,  9.4000],\n",
              "         [ 5.5000,  0.2900,  0.3000,  ...,  3.3400,  0.3800, 12.8000],\n",
              "         [ 6.0000,  0.2100,  0.3800,  ...,  3.2600,  0.3200, 11.8000]]),\n",
              " torch.Size([4898, 11]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NiUNJjVbk4kr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0d68d6e8-d6b3-4e45-c470-60c396a2007c"
      },
      "source": [
        "# Select all rows and the last column\n",
        "target = wineq[:, -1]\n",
        "target, target.shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([6., 6., 6.,  ..., 6., 7., 6.]), torch.Size([4898]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m9DObdNzmP6i",
        "colab_type": "text"
      },
      "source": [
        "If you want to transform the target tensor in a tensor of labels, you have two options, depending on the strategy or how you want to use the categorical data.\n",
        "\n",
        "1. One option is to treat a label as an integer vector of scores\n",
        "2. The other approach is to build a one-hot encoding of the scores"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RbBf91ZxlaJo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5a08b4f3-c16b-4f4b-bc47-186e6b3c5fe0"
      },
      "source": [
        "target = wineq[:, -1].long()\n",
        "target"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([6, 6, 6,  ..., 6, 7, 6])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YsKz25rCmzpw",
        "colab_type": "text"
      },
      "source": [
        "If targets were string labels (such as wine color), assigning an integer number to each string would allow you to follow the same approach.\n",
        "\n",
        "The other approach is to build a one-hot encoding of the scores—that is, encode\n",
        "each of the ten scores in a vector of ten elements, with all elements set to zero but one, at a different index for each score. \n",
        "\n",
        "This way, a score of 1 could be mapped to the vector (1,0,0,0,0,0,0,0,0,0), a score of 5 to (0,0,0,0,1,0,0,0,0,0) and so on.\n",
        "\n",
        "**One-hot encoding is appropriate for quantitative scores when fractional values between integer scores (such as 2.4) make no sense for the application (when score is either this or that).**\n",
        "\n",
        "You can achieve one-hot encoding by using the scatter_ method, which fills the\n",
        "tensor with values from a source tensor along the indices provided as arguments."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fjrJXnTbmtbQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "f595b9dd-73c4-4e2e-a427-30dbf98736ce"
      },
      "source": [
        "target_onehot = torch.zeros(target.shape[0], 10)\n",
        "target_onehot.scatter_(1, target.unsqueeze(1), 1.0)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 0., 0.,  ..., 1., 0., 0.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IGAx_l7joggm",
        "colab_type": "text"
      },
      "source": [
        "First, notice that its name ends with an underscore. This convention in PyTorch indicates that the method won’t return a new tensor but modify the tensor in place. The arguments for scatter_ are:\n",
        "\n",
        "* The dimension along which the following two arguments are specified\n",
        "* A column tensor indicating the indices of the elements to scatter\n",
        "* A tensor containing the elements to scatter or a single scalar to scatter (1,in this case)\n",
        "\n",
        "The second argument of scatter_, the index tensor, is required to have the same\n",
        "number of dimensions as the tensor you scatter into. Because target_onehot has two dimensions (4898x10), you need to add an extra dummy dimension to target by\n",
        "using unsqueeze:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6cylv6JNoFqh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "fc841002-7508-481d-9ad4-d8a791b8fcec"
      },
      "source": [
        "target_unsqueezed = target.unsqueeze(1)\n",
        "target_unsqueezed"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[6],\n",
              "        [6],\n",
              "        ...,\n",
              "        [7],\n",
              "        [6]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u7MeApBSp5aK",
        "colab_type": "text"
      },
      "source": [
        "The call to unsqueeze adds a singleton dimension, from a 1D tensor of 4898 elements to a 2D tensor of size (4898x1), without changing its contents.\n",
        "\n",
        "**PyTorch allows you to use class indices directly as targets while training neural networks. If you want to use the score as a categorical input to the network, however, you’d have to transform it to a one-hot encoded tensor.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pnJYKhtkqohJ",
        "colab_type": "text"
      },
      "source": [
        "### Data normalization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hTcDW_xlqrJx",
        "colab_type": "text"
      },
      "source": [
        "Now go back to your data tensor, containing the 11 variables associated with the\n",
        "chemical analysis. You can use the functions in the PyTorch Tensor API to manipulate your data in tensor form. \n",
        "\n",
        "First, obtain means and standard deviations for each column:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZgIdSHtjpm7I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}